# üìã LogiQ AI - Resumen del Proyecto

## üéØ Descripci√≥n General

**LogiQ AI** es un asistente conversacional que permite consultar un data warehouse log√≠stico mediante lenguaje natural. Integra datos de 4 fuentes diferentes (Tera, Cloudfleet, Scania, Keeper), los normaliza a un schema can√≥nico, y utiliza Gemini AI para convertir preguntas en SQL seguro.

---

## üöÄ Comandos R√°pidos

### Instalaci√≥n y Ejecuci√≥n (3 comandos)

```bash
# 1. Setup: instalar dependencias
./setup.sh

# 2. Backend: cargar datos y levantar API
./run_backend.sh

# 3. Frontend: abrir UI (en otra terminal)
./run_frontend.sh
```

### Demo Completo

```bash
./demo/run_demo.sh
```

---

## üì° Endpoints de la API

### Base URL
```
http://localhost:8000
```

### Endpoints Disponibles

#### 1. Health Check
```bash
GET /health

# Ejemplo:
curl http://localhost:8000/health
```

**Response:**
```json
{
  "status": "healthy",
  "database": "connected",
  "trucks_count": 50
}
```

---

#### 2. Schema Can√≥nico
```bash
GET /schema

# Ejemplo:
curl http://localhost:8000/schema
```

**Response:**
```json
{
  "tables": {
    "trucks": {
      "columns": ["truck_id", "plate", "model", "brand", "driver_id", "region", "status"],
      "primary_key": "truck_id"
    },
    ...
  }
}
```

---

#### 3. Query (Principal)
```bash
POST /query
Content-Type: application/json

{
  "user": "user_id",
  "nl": "pregunta en lenguaje natural"
}
```

**Ejemplo 1:**
```bash
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{
    "user": "demo_user",
    "nl": "¬øQu√© cami√≥n tuvo m√°s alertas de temperatura en la √∫ltima semana?"
  }'
```

**Response:**
```json
{
  "nl": "¬øQu√© cami√≥n tuvo m√°s alertas de temperatura en la √∫ltima semana?",
  "sql": "SELECT truck_id, COUNT(*) as alerts FROM alerts WHERE alert_type = 'temperature' AND timestamp >= datetime('now', '-7 days') GROUP BY truck_id ORDER BY alerts DESC LIMIT 5;",
  "rows": [
    {"truck_id": "TRUCK_042", "alerts": 15},
    {"truck_id": "TRUCK_023", "alerts": 12},
    ...
  ],
  "explanation": "El cami√≥n TRUCK_042 tuvo 15 alertas de temperatura en la √∫ltima semana...",
  "execution_time_ms": 234.5,
  "rows_count": 5
}
```

---

#### 4. Logs
```bash
GET /logs?limit=50

# Ejemplo:
curl http://localhost:8000/logs?limit=10
```

**Response:**
```json
{
  "logs": [
    {
      "timestamp": "2025-10-21T13:15:30Z",
      "user": "demo_user",
      "nl": "Lista de camiones",
      "sql": "SELECT * FROM trucks LIMIT 1000;",
      "exec_time_ms": 45.2,
      "rows_count": 50,
      "error": null
    },
    ...
  ]
}
```

---

## üéØ 10 Queries Demo

### 1. Alertas de Temperatura
```
¬øQu√© cami√≥n tuvo m√°s alertas de temperatura en la √∫ltima semana?
```
**Resultado esperado**: Top 5 camiones con m√°s alertas de tipo "temperature"

---

### 2. Consumo por Marca
```
Promedio de consumo por marca de cami√≥n en los √∫ltimos 30 d√≠as
```
**Resultado esperado**: AVG(fuel_level) agrupado por brand

---

### 3. Viajes Finalizados
```
¬øCu√°ntos viajes finalizados hubo ayer?
```
**Resultado esperado**: COUNT de trips con status='finished' y fecha de ayer

---

### 4. Alertas Cr√≠ticas
```
Mostrar las 10 √∫ltimas alertas cr√≠ticas
```
**Resultado esperado**: 10 alertas con severity='critical' ordenadas por timestamp DESC

---

### 5. Camiones en Mantenimiento
```
Lista de camiones actualmente en mantenimiento
```
**Resultado esperado**: Camiones con status='maintenance'

---

### 6. Rutas con Retrasos
```
Top 5 rutas con m√°s retrasos
```
**Resultado esperado**: Rutas (origin-destination) con mayor duraci√≥n promedio

---

### 7. Top Conductor
```
¬øCu√°l es el conductor con m√°s kil√≥metros recorridos este mes?
```
**Resultado esperado**: Conductor con mayor SUM(distance_km) en √∫ltimos 30 d√≠as

---

### 8. Alertas de Velocidad
```
Alertas de velocidad excesiva en la √∫ltima semana
```
**Resultado esperado**: Alertas de tipo "speed" en √∫ltimos 7 d√≠as

---

### 9. Combustible Bajo
```
Camiones con nivel de combustible bajo (< 20%)
```
**Resultado esperado**: Camiones con fuel_level < 20

---

### 10. Viajes Largos por Regi√≥n
```
Viajes m√°s largos por regi√≥n
```
**Resultado esperado**: Top viajes ordenados por distance_km, agrupados por regi√≥n

---

## üìä Schema Can√≥nico

### Tabla: trucks
```sql
CREATE TABLE trucks (
    truck_id TEXT PRIMARY KEY,
    plate TEXT,
    model TEXT,
    brand TEXT,
    driver_id TEXT,
    region TEXT,
    status TEXT
);
```
**Registros**: 50 camiones

---

### Tabla: drivers
```sql
CREATE TABLE drivers (
    driver_id TEXT PRIMARY KEY,
    name TEXT,
    license TEXT
);
```
**Registros**: 60 conductores

---

### Tabla: trips
```sql
CREATE TABLE trips (
    trip_id TEXT PRIMARY KEY,
    truck_id TEXT,
    origin TEXT,
    destination TEXT,
    start_time TEXT,
    end_time TEXT,
    distance_km REAL,
    status TEXT,
    FOREIGN KEY (truck_id) REFERENCES trucks(truck_id)
);
```
**Registros**: 500 viajes

---

### Tabla: telemetry
```sql
CREATE TABLE telemetry (
    telemetry_id TEXT PRIMARY KEY,
    truck_id TEXT,
    timestamp TEXT,
    speed_kmh REAL,
    fuel_level REAL,
    engine_temp_c REAL,
    FOREIGN KEY (truck_id) REFERENCES trucks(truck_id)
);
```
**Registros**: 2000 registros (1000 de Cloudfleet + 1000 de Scania)

---

### Tabla: alerts
```sql
CREATE TABLE alerts (
    alert_id TEXT PRIMARY KEY,
    truck_id TEXT,
    timestamp TEXT,
    alert_type TEXT,
    severity TEXT,
    description TEXT,
    FOREIGN KEY (truck_id) REFERENCES trucks(truck_id)
);
```
**Registros**: 300 alertas

---

## üß™ Tests

### Ejecutar Todos los Tests
```bash
source venv/bin/activate
pytest tests/ -v
```

### Tests Espec√≠ficos

**Adapters:**
```bash
pytest tests/test_adapters.py -v
```

**SQL Validator:**
```bash
pytest tests/test_sql_validator.py -v
```

**End-to-End:**
```bash
# Primero iniciar el backend
./run_backend.sh

# En otra terminal:
pytest tests/test_end_to_end.py -v
```

---

## üîß Configuraci√≥n

### Variables de Entorno (.env)

```bash
# API Keys (configurar al menos una)
GEMINI_API_KEY=your_gemini_api_key_here
# OPENAI_API_KEY=your_openai_key_here

# BigQuery (opcional)
USE_BIGQUERY=false
# BQ_PROJECT=your-gcp-project
# BQ_DATASET=logiq_warehouse

# Configuraci√≥n
PORT=8000
DB_PATH=data/logiq.db
LOG_PATH=logs/queries.log
```

### Modo Mock vs API Real

**Sin API Key (Modo Mock)**:
- Usa templates predefinidos para generar SQL
- Funcional para demo y desarrollo
- No requiere conexi√≥n a internet

**Con API Key (Modo Real)**:
- Usa Gemini AI para NL ‚Üí SQL
- Mejor calidad de SQL generado
- Soporta queries m√°s complejas

---

## üìÅ Estructura de Archivos

```
logiq-ai-proto/
‚îú‚îÄ‚îÄ README.md                 # Documentaci√≥n principal
‚îú‚îÄ‚îÄ SUMMARY.md               # Este archivo
‚îú‚îÄ‚îÄ TODO.md                  # Tareas pendientes
‚îú‚îÄ‚îÄ setup.sh                 # Script de instalaci√≥n
‚îú‚îÄ‚îÄ run_backend.sh           # Iniciar backend
‚îú‚îÄ‚îÄ run_frontend.sh          # Iniciar frontend
‚îú‚îÄ‚îÄ .env                     # Variables de entorno
‚îú‚îÄ‚îÄ .gitignore              # Git ignore
‚îÇ
‚îú‚îÄ‚îÄ data/                    # Datos y base de datos
‚îÇ   ‚îú‚îÄ‚îÄ tera_trips.csv
‚îÇ   ‚îú‚îÄ‚îÄ cloudfleet_positions.csv
‚îÇ   ‚îú‚îÄ‚îÄ scania_metrics.csv
‚îÇ   ‚îú‚îÄ‚îÄ keeper_alerts.csv
‚îÇ   ‚îú‚îÄ‚îÄ master_trucks.csv
‚îÇ   ‚îú‚îÄ‚îÄ master_drivers.csv
‚îÇ   ‚îî‚îÄ‚îÄ logiq.db            # SQLite database
‚îÇ
‚îú‚îÄ‚îÄ adapters/               # Transformadores de datos
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ adapter_base.py
‚îÇ   ‚îú‚îÄ‚îÄ tera_adapter.py
‚îÇ   ‚îú‚îÄ‚îÄ cloudfleet_adapter.py
‚îÇ   ‚îú‚îÄ‚îÄ scania_adapter.py
‚îÇ   ‚îî‚îÄ‚îÄ keeper_adapter.py
‚îÇ
‚îú‚îÄ‚îÄ mappings/               # Configuraciones YAML
‚îÇ   ‚îú‚îÄ‚îÄ tera_mapping.yaml
‚îÇ   ‚îú‚îÄ‚îÄ cloudfleet_mapping.yaml
‚îÇ   ‚îú‚îÄ‚îÄ scania_mapping.yaml
‚îÇ   ‚îî‚îÄ‚îÄ keeper_mapping.yaml
‚îÇ
‚îú‚îÄ‚îÄ backend/                # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ app.py             # Aplicaci√≥n principal
‚îÇ   ‚îî‚îÄ‚îÄ lib/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ validate_sql.py
‚îÇ       ‚îî‚îÄ‚îÄ gemini_client.py
‚îÇ
‚îú‚îÄ‚îÄ frontend/               # Streamlit UI
‚îÇ   ‚îî‚îÄ‚îÄ streamlit_app.py
‚îÇ
‚îú‚îÄ‚îÄ scripts/                # Scripts de utilidad
‚îÇ   ‚îú‚îÄ‚îÄ generate_data.py   # Generar CSVs simulados
‚îÇ   ‚îî‚îÄ‚îÄ load_data.py       # Cargar datos en SQLite
‚îÇ
‚îú‚îÄ‚îÄ tests/                  # Tests automatizados
‚îÇ   ‚îú‚îÄ‚îÄ test_adapters.py
‚îÇ   ‚îú‚îÄ‚îÄ test_sql_validator.py
‚îÇ   ‚îî‚îÄ‚îÄ test_end_to_end.py
‚îÇ
‚îú‚îÄ‚îÄ demo/                   # Assets de demostraci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ run_demo.sh
‚îÇ   ‚îî‚îÄ‚îÄ demo_script.md
‚îÇ
‚îú‚îÄ‚îÄ slides/                 # Presentaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ pitch.md
‚îÇ
‚îî‚îÄ‚îÄ logs/                   # Logs de queries
    ‚îú‚îÄ‚îÄ queries.log
    ‚îî‚îÄ‚îÄ backend.log
```

---

## üîí Seguridad

### Validador SQL

**Reglas Implementadas:**
1. ‚úÖ Solo permite `SELECT` y `WITH`
2. ‚ùå Bloquea `DROP`, `DELETE`, `UPDATE`, `INSERT`, `ALTER`, `EXEC`
3. ‚úÖ Whitelist de tablas (solo schema can√≥nico)
4. ‚úÖ Auto-LIMIT 1000 (previene queries masivas)
5. ‚ùå Detecta m√∫ltiples statements (`;` en medio)
6. ‚ùå Bloquea comentarios SQL (`--`, `/*`)
7. ‚úÖ L√≠mite m√°ximo: 10,000 filas

### Auditor√≠a

Todos los queries se registran en `logs/queries.log`:
- Timestamp
- Usuario
- Query original (NL)
- SQL generado
- Tiempo de ejecuci√≥n
- N√∫mero de resultados
- Errores (si los hay)

---

## üìà Performance

### M√©tricas Esperadas

**Tiempo de Respuesta:**
- Query simple: < 500ms
- Query con JOIN: < 1s
- Query compleja: < 2s
- Objetivo: < 5s (criterio de aceptaci√≥n)

**Capacidad:**
- 10K queries/d√≠a
- 100 usuarios concurrentes
- Base de datos: 2500+ registros

**Recursos:**
- RAM: ~200MB
- CPU: < 10% en idle
- Disco: ~50MB (SQLite)

---

## üêõ Troubleshooting

### Backend no inicia

**Error**: `Base de datos no encontrada`
```bash
# Soluci√≥n:
python3 scripts/generate_data.py
python3 scripts/load_data.py
```

---

### Frontend no conecta

**Error**: `No se puede conectar al backend`
```bash
# Verificar que el backend est√© corriendo:
curl http://localhost:8000/health

# Si no responde, iniciar backend:
./run_backend.sh
```

---

### Gemini API no funciona

**Error**: `Error configurando Gemini`
```bash
# Verificar API key en .env:
cat .env | grep GEMINI_API_KEY

# Si no est√° configurada, el sistema usa modo mock autom√°ticamente
```

---

### Tests fallan

**Error**: `API no est√° corriendo`
```bash
# Para tests e2e, primero iniciar backend:
./run_backend.sh

# En otra terminal:
pytest tests/test_end_to_end.py -v
```

---

## üöÄ Pr√≥ximos Pasos

### Para Desarrollo

1. **Configurar API Key**:
   - Obtener Gemini API key
   - Agregar a `.env`
   - Reiniciar backend

2. **Agregar M√°s Datos**:
   - Editar `scripts/generate_data.py`
   - Aumentar `NUM_TRIPS`, `NUM_TELEMETRY`, etc.
   - Re-ejecutar `load_data.py`

3. **Personalizar Queries**:
   - Editar `backend/lib/gemini_client.py`
   - Agregar m√°s ejemplos en `SYSTEM_PROMPT`
   - Mejorar templates en `_mock_nl_to_sql`

### Para Producci√≥n

1. **Integraci√≥n Real**:
   - Conectar APIs de Tera, Cloudfleet, Scania, Keeper
   - Implementar ETL automatizado
   - Sincronizaci√≥n en tiempo real

2. **Escalabilidad**:
   - Migrar a BigQuery
   - Implementar cach√© (Redis)
   - Load balancing

3. **Seguridad**:
   - Autenticaci√≥n (OAuth2/JWT)
   - Rate limiting
   - Encriptaci√≥n de datos sensibles

4. **Monitoreo**:
   - Prometheus + Grafana
   - Alertas autom√°ticas
   - Logging centralizado

---

## üìû Soporte

### Documentaci√≥n
- `README.md` - Gu√≠a principal
- `demo/demo_script.md` - Script de presentaci√≥n
- `slides/pitch.md` - Presentaci√≥n completa

### Contacto
- üìß Email: logiq-ai@santex.com
- üíº LinkedIn: /logiq-ai
- üåê Web: logiq-ai.demo

---

## üìÑ Licencia

MIT License - Ver LICENSE file

---

**Desarrollado para GLAC Hackathon 2025** üöÄ
